.equ REG_DZERO 0
.equ REG_DU0 1
.equ REG_DU1 2
.equ REG_DU2 3
.equ REG_DU3 4
.equ REG_DU4 5
.equ REG_DU5 6
.equ REG_DU6 7
.equ REG_DU7 8
.equ REG_DU8 9
.equ REG_DU9 10
.equ REG_DU10 11
.equ REG_DU11 12
.equ REG_DLR 13
.equ REG_DFP 14
.equ REG_DSP 15

.equ SYSC_DISP_REGS 0
.equ SYSC_DISP_DDEST_VECTOR_DATA 1
.equ SYSC_DISP_DDEST_SCALAR_DATA 2
.equ SYSC_DISP_DDEST_ADDR 3
.equ SYSC_FINISH 4

.equ NUM_BYTES__SIZE_8 (8 / 8)
.equ NUM_BYTES__SIZE_16 (16 / 8)
.equ NUM_BYTES__SIZE_32 (32 / 8)
.equ NUM_BYTES__SIZE_64 (64 / 8)
.equ NUM_BYTES__LAR_DATA (4 * NUM_BYTES__SIZE_64)

.equ LOG2_OF_NUM_BYTES__SIZE_8 0
.equ LOG2_OF_NUM_BYTES__SIZE_16 1
.equ LOG2_OF_NUM_BYTES__SIZE_32 2
.equ LOG2_OF_NUM_BYTES__SIZE_64 3
.equ LOG2_OF_NUM_BYTES__LAR_DATA 5


start:
{
	// We don't need a pc-relative load in this case.
	ldu64 dsp, dzero, dzero, gvar__stack_pointer
	ldu64 dfp, dzero, dzero, gvar__frame_pointer


	//sim_syscall dsp, dzero, dzero, SYSC_DISP_DDEST_SCALAR_DATA
	//sim_syscall dfp, dzero, dzero, SYSC_DISP_DDEST_SCALAR_DATA
	//sim_syscall dsp, dzero, dzero, SYSC_DISP_DDEST_ADDR
	//sim_syscall dfp, dzero, dzero, SYSC_DISP_DDEST_ADDR
	//sim_syscall dzero, dzero, dzero, SYSC_FINISH

	.equ __LOCAL_STACK_SPACE NUM_BYTES__LAR_DATA
	.equ __LOCAL_SP_OFFSET__TEMP (0 * NUM_BYTES__SIZE_64)

	.equ __LOCAL_FP_OFFSET__COPY_OF_MAIN_RET_VAL \
		(-(1 * NUM_BYTES__SIZE_64))


	//ldu8 dfp, dsp, dzero, 0
	//ldu8 dsp, dsp, dzero, -__LOCAL_STACK_SPACE
	cpys dfp, dsp
	addis dsp, dsp, -__LOCAL_STACK_SPACE



	.equ __CALL_MAIN_STACK_SPACE (1 * NUM_BYTES__LAR_DATA)
	.equ __CALL_MAIN_SP_OFFSET__RETURN_ADDR (3 * NUM_BYTES__SIZE_64)
	.equ __CALL_MAIN_SP_OFFSET__RETURN_VAL (2 * NUM_BYTES__SIZE_64)


	addis dsp, dsp, -__CALL_MAIN_STACK_SPACE

	ldu64 dlr, dzero, dsp, __CALL_MAIN_SP_OFFSET__RETURN_ADDR

	bl main


__after_call_main:
	// Restore dfp
	addis dfp, dfp, (__CALL_MAIN_STACK_SPACE + __LOCAL_STACK_SPACE)


	// Copy main()'s return value to outside the partial stack frame
	ldu64 du3, dzero, dfp, __LOCAL_FP_OFFSET__COPY_OF_MAIN_RET_VAL
	ldu64 du1, dzero, dsp, __CALL_MAIN_SP_OFFSET__RETURN_VAL
	cpys du3, du1


	// Restore dsp
	addis dsp, dsp, __CALL_MAIN_STACK_SPACE

__finish:
	sim_syscall du3, dzero, dzero, SYSC_DISP_DDEST_SCALAR_DATA
	sim_syscall dzero, dzero, dzero, SYSC_FINISH

__infin:
	bra __infin

.dataalign
__pool:

}

.equ ARR_SIZE__TO_ADD 10

.dataalign
global_constants:
gconst_to_add_arr_a:
	.db64 0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9
.dataalign
gconst_to_add_arr_b:
	.db64 0x10, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16, 0x17, 0x18, 0x19

.dataalign
global_vars:
gvar__stack_pointer:
	.db64 0x10000
gvar__frame_pointer:
	.db64 0

.dataalign
gvar_to_scalar_add_arr_c:
	.space (ARR_SIZE__TO_ADD * NUM_BYTES__SIZE_64)
.dataalign
gvar_to_vector_add_arr_c:
	.space (ARR_SIZE__TO_ADD * NUM_BYTES__SIZE_64)


.codealign
main:
{
	.equ __LOCAL_STACK_SPACE (1 * NUM_BYTES__LAR_DATA)
	.equ __LOCAL_SP_OFFSET__TEMP_0 (0 * NUM_BYTES__SIZE_64)
	.equ __LOCAL_SP_OFFSET__TEMP_1 (1 * NUM_BYTES__SIZE_64)
	.equ __LOCAL_SP_OFFSET__TEMP_2 (2 * NUM_BYTES__SIZE_64)
	.equ __LOCAL_SP_OFFSET__TEMP_3 (3 * NUM_BYTES__SIZE_64)


	.equ __LOCAL_FP_OFFSET__RETURN_ADDR (3 * NUM_BYTES__SIZE_64)
	.equ __LOCAL_FP_OFFSET__RETURN_VAL (2 * NUM_BYTES__SIZE_64)
	cpys dfp, dsp
	addis dsp, dsp, -__LOCAL_STACK_SPACE



	.equ GC__TO_ADD_ARR_A REG_DU8
	.equ GC__TO_ADD_ARR_B REG_DU9
	.equ GV__TO_SCALAR_ADD_ARR_C REG_DU10
	.equ GV__TO_VECTOR_ADD_ARR_C REG_DU11


	ldu64 du0, dzero, dfp, __LOCAL_FP_OFFSET__RETURN_VAL
	ldu64 du1, dzero, dsp, __LOCAL_SP_OFFSET__TEMP_0
	ldu64 du2, dzero, dsp, __LOCAL_SP_OFFSET__TEMP_1
	ldu64 du3, dzero, dsp, __LOCAL_SP_OFFSET__TEMP_2
	ldu64 du4, dzero, dsp, __LOCAL_SP_OFFSET__TEMP_3


	.equ __LOCAL_POOL_OFFSET__TO_ADD_ARR_A (0 * NUM_BYTES__SIZE_64)
	.equ __LOCAL_POOL_OFFSET__TO_ADD_ARR_B (1 * NUM_BYTES__SIZE_64)
	.equ __LOCAL_POOL_OFFSET__TO_SCALAR_ADD_ARR_C (2 * NUM_BYTES__SIZE_64)
	.equ __LOCAL_POOL_OFFSET__TO_VECTOR_ADD_ARR_C (3 * NUM_BYTES__SIZE_64)






	pcrels du0, __pool

	//sim_syscall du0, dzero, dzero, SYSC_DISP_DDEST_SCALAR_DATA

	// Scalar add
	{
		ldu64 GC__TO_ADD_ARR_A, dzero, du0, \
			__LOCAL_POOL_OFFSET__TO_ADD_ARR_A
		ldu64 GC__TO_ADD_ARR_B, dzero, du0, \
			__LOCAL_POOL_OFFSET__TO_ADD_ARR_B
		ldu64 GV__TO_SCALAR_ADD_ARR_C, dzero, du0, \
			__LOCAL_POOL_OFFSET__TO_SCALAR_ADD_ARR_C

		ldu64 GC__TO_ADD_ARR_A, dzero, GC__TO_ADD_ARR_A, 0
		ldu64 GC__TO_ADD_ARR_B, dzero, GC__TO_ADD_ARR_B, 0
		ldu64 GV__TO_SCALAR_ADD_ARR_C, dzero, GV__TO_SCALAR_ADD_ARR_C, 0


		.equ V__I REG_DU1
		.equ V__CMP_TEMP REG_DU2


		// for (i=0; i<ARR_SIZE__TO_ADD; ++i)
		// i = 0;
		cpyis V__I, 0
		__loop:
		{
			// if (i == ARR_SIZE__TO_ADD) goto __after_loop
			addis V__CMP_TEMP, V__I, -ARR_SIZE__TO_ADD
			bfal V__CMP_TEMP, __after_loop

			adds GV__TO_SCALAR_ADD_ARR_C, GC__TO_ADD_ARR_A, \
				GC__TO_ADD_ARR_B
			ldu64 GV__TO_SCALAR_ADD_ARR_C, GV__TO_SCALAR_ADD_ARR_C, \
				dzero, NUM_BYTES__SIZE_64
			ldu64 GC__TO_ADD_ARR_A, GC__TO_ADD_ARR_A, \
				dzero, NUM_BYTES__SIZE_64
			ldu64 GC__TO_ADD_ARR_B, GC__TO_ADD_ARR_B, \
				dzero, NUM_BYTES__SIZE_64

			// ++i;
			addis V__I, V__I, 1

			// goto __loop
			bra __loop
		}
		__after_loop:
	}

	// Display scalar retuls
	{
		ldu64 GV__TO_SCALAR_ADD_ARR_C, dzero, du0, \
			__LOCAL_POOL_OFFSET__TO_SCALAR_ADD_ARR_C
		ldu64 GV__TO_SCALAR_ADD_ARR_C, dzero, GV__TO_SCALAR_ADD_ARR_C, 0


		.equ V__I REG_DU1
		.equ V__CMP_TEMP REG_DU2


		// for (i=0; i<ARR_SIZE__TO_ADD; ++i)
		// i = 0;
		cpyis V__I, 0
		__loop:
		{
			addis V__CMP_TEMP, V__I, -ARR_SIZE__TO_ADD
			bfal V__CMP_TEMP, __after_loop

			sim_syscall GV__TO_SCALAR_ADD_ARR_C, dzero, dzero, \
				SYSC_DISP_DDEST_SCALAR_DATA
			ldu64 GV__TO_SCALAR_ADD_ARR_C, GV__TO_SCALAR_ADD_ARR_C, \
				dzero, NUM_BYTES__SIZE_64


			addis V__I, V__I, 1
			bra __loop
		}
		__after_loop:
	}

	//// Vector add
	//{
	//	.equ NUM_BYTES__TO_ADD (ARR_SIZE__TO_ADD * NUM_BYTES__SIZE_64)

	//	.equ NUM_BYTES__TO_PURE_VECTOR_ADD \
	//		.align2curr(NUM_BYTES__TO_ADD, LOG2_OF_NUM_BYTES__LAR_DATA)
	//	.equ NUM_BYTES__CAN_NOT_PURE_VECTOR_ADD \
	//		(NUM_BYTES__TO_ADD - NUM_BYTES__TO_PURE_VECTOR_ADD)
	//	.equ ARR_SIZE__TO_PURE_VECTOR_ADD \
	//		(NUM_BYTES__TO_PURE_VECTOR_ADD / NUM_BYTES__SIZE_64)
	//	.equ ARR_SIZE__CAN_NOT_PURE_VECTOR_ADD \
	//		(ARR_SIZE__TO_ADD - ARR_SIZE__TO_PURE_VECTOR_ADD)
	//}




__finish:
	addis dsp, dsp, __LOCAL_STACK_SPACE
	jmp dlr


.dataalign
__pool:
	.db64 gconst_to_add_arr_a
	.db64 gconst_to_add_arr_b
	.db64 gvar_to_scalar_add_arr_c
	.db64 gvar_to_vector_add_arr_c
}
